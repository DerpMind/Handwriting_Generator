{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI-Guru/ngdlm.git\n",
      "  Cloning https://github.com/AI-Guru/ngdlm.git to /tmp/pip-req-build-d634hs5s\n",
      "Requirement already satisfied (use --upgrade to upgrade): ngdlm==0.0.2rc1 from git+https://github.com/AI-Guru/ngdlm.git in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages\n",
      "Requirement already satisfied: keras in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from ngdlm==0.0.2rc1) (2.2.2)\n",
      "Requirement already satisfied: tensorflow in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from ngdlm==0.0.2rc1) (1.10.0)\n",
      "Requirement already satisfied: matplotlib in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from ngdlm==0.0.2rc1) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from keras->ngdlm==0.0.2rc1) (1.15.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from keras->ngdlm==0.0.2rc1) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from keras->ngdlm==0.0.2rc1) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from keras->ngdlm==0.0.2rc1) (3.13)\n",
      "Requirement already satisfied: h5py in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from keras->ngdlm==0.0.2rc1) (2.8.0)\n",
      "Requirement already satisfied: keras_applications==1.0.4 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from keras->ngdlm==0.0.2rc1) (1.0.4)\n",
      "Requirement already satisfied: keras_preprocessing==1.0.2 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from keras->ngdlm==0.0.2rc1) (1.0.2)\n",
      "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorflow->ngdlm==0.0.2rc1) (1.10.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorflow->ngdlm==0.0.2rc1) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorflow->ngdlm==0.0.2rc1) (0.4.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorflow->ngdlm==0.0.2rc1) (1.12.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorflow->ngdlm==0.0.2rc1) (0.2.0)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorflow->ngdlm==0.0.2rc1) (39.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorflow->ngdlm==0.0.2rc1) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorflow->ngdlm==0.0.2rc1) (0.7.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorflow->ngdlm==0.0.2rc1) (0.31.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from matplotlib->ngdlm==0.0.2rc1) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from matplotlib->ngdlm==0.0.2rc1) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from matplotlib->ngdlm==0.0.2rc1) (2.7.3)\n",
      "Requirement already satisfied: pytz in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from matplotlib->ngdlm==0.0.2rc1) (2018.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from matplotlib->ngdlm==0.0.2rc1) (1.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow->ngdlm==0.0.2rc1) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/lorenz/.conda/envs/Basics/lib/python3.6/site-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow->ngdlm==0.0.2rc1) (2.6.11)\n",
      "Building wheels for collected packages: ngdlm\n",
      "  Running setup.py bdist_wheel for ngdlm ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-hgzug5et/wheels/93/06/27/e156acb49f475c364c3c9fa4ad4ab7bfa38808bff5bf9c4647\n",
      "Successfully built ngdlm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob2 as glob\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import NGDLM models.\n",
    "!pip install git+https://github.com/AI-Guru/ngdlm.git\n",
    "from ngdlm import models as ngdlmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, initializers\n",
    "from ngdlm import models as ngdlmodels\n",
    "from ngdlm import utils as ngdlutils\n",
    "from keras import models, layers\n",
    "from keras import initializers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 32) 320         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 32)   9248        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 32768)        0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1024)         33555456    flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 64)           65600       dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 10)           650         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 10)           650         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 10)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 33,631,924\n",
      "Trainable params: 33,631,924\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Decoder:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                704       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32768)             33587200  \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 128, 128, 1)       289       \n",
      "=================================================================\n",
      "Total params: 33,673,249\n",
      "Trainable params: 33,673,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Autoencoder:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 10), (None, 10),  33631924  \n",
      "_________________________________________________________________\n",
      "model_6 (Model)              (None, 128, 128, 1)       33673249  \n",
      "=================================================================\n",
      "Total params: 67,305,173\n",
      "Trainable params: 67,305,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "\n",
    "# Encoder.\n",
    "encoder_input = layers.Input(shape=(128, 128,1))\n",
    "encoder_output = layers.Conv2D(32, (3, 3),\n",
    "                               kernel_initializer=initializers.lecun_normal(seed=0),\n",
    "                               activation=\"relu\",\n",
    "                               padding=\"same\")(encoder_input)\n",
    "encoder_output = layers.MaxPooling2D((2, 2),padding=\"same\")(encoder_output)\n",
    "encoder_output = layers.Conv2D(32, (3, 3),\n",
    "                               kernel_initializer=initializers.lecun_normal(seed=0),\n",
    "                               activation=\"relu\",\n",
    "                               padding=\"same\")(encoder_output)\n",
    "encoder_output = layers.MaxPooling2D((2, 2),padding=\"same\")(encoder_output)\n",
    "encoder_output = layers.Flatten()(encoder_output)\n",
    "encoder_output = layers.Dense(1024,\n",
    "                              activation = \"relu\",\n",
    "                              kernel_initializer=initializers.lecun_normal(seed=0)\n",
    "                             )(encoder_output)\n",
    "encoder_output = layers.Dense(64,\n",
    "                              activation = \"relu\",\n",
    "                              kernel_initializer=initializers.lecun_normal(seed=0)\n",
    "                             )(encoder_output)\n",
    "encoder = models.Model(encoder_input, encoder_output)\n",
    "\n",
    "# Decoder.\n",
    "decoder_input = layers.Input(shape=(latent_dim,))\n",
    "decoder_output = layers.Dense(64,\n",
    "                              activation=\"relu\",\n",
    "                              kernel_initializer=initializers.lecun_normal(seed=0)\n",
    "                             )(decoder_input)\n",
    "decoder_output = layers.Dense(1024,\n",
    "                              activation=\"sigmoid\",\n",
    "                              kernel_initializer=initializers.lecun_normal(seed=0)\n",
    "                             )(decoder_output)\n",
    "decoder_output = layers.Dense(32*32*32,\n",
    "                              activation=\"sigmoid\",\n",
    "                              kernel_initializer=initializers.lecun_normal(seed=0)\n",
    "                             )(decoder_output)\n",
    "decoder_output = layers.Reshape((32, 32, 32))(decoder_output)\n",
    "decoder_output = layers.Conv2D(32, (3, 3),\n",
    "                               kernel_initializer=initializers.lecun_normal(seed=0),\n",
    "                               activation=\"relu\",\n",
    "                               padding=\"same\")(decoder_output)\n",
    "decoder_output = layers.UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = layers.Conv2D(32, (3, 3),\n",
    "                               kernel_initializer=initializers.lecun_normal(seed=0),\n",
    "                               activation=\"relu\",\n",
    "                               padding=\"same\")(decoder_output)\n",
    "decoder_output = layers.UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = layers.Conv2D(1, (3, 3),\n",
    "                               kernel_initializer=initializers.lecun_normal(seed=0),\n",
    "                               activation=\"sigmoid\",\n",
    "                               padding=\"same\")(decoder_output)\n",
    "decoder = models.Model(decoder_input, decoder_output)\n",
    "\n",
    "# Autoencoder.\n",
    "autoencoder = ngdlmodels.VAE(encoder, decoder, latent_dim=latent_dim)    #glue encoder and decoder together\n",
    "autoencoder.compile(optimizer=\"adadelta\", loss=\"binary_crossentropy\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train- and validation-data.\n",
    "from PIL import Image\n",
    "import glob2 as glob\n",
    "from aux_functions import helpers\n",
    "\n",
    "image_list = []\n",
    "for filename in glob.glob('../data/a/*.png'): #assuming gif\n",
    "    im=np.array(Image.open(filename))\n",
    "    im=helpers.rgb2gray(im)\n",
    "    image_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(image_list, open(\"../data/pickled_a.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input_train = np.array(image_list)\n",
    "#(x_train, _), (x_test, _)= mnist.load_data()\n",
    "\n",
    "x_input_train = x_input_train.astype('float32')/255.0\n",
    "#x_input_validate = x_test.astype('float32')/255.0 \n",
    "\n",
    "x_input_train = x_input_train.reshape((-1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 128, 128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/10\n",
      "127/369 [=========>....................] - ETA: 49s - loss: 2.4773"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-fcd26e842e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#validation_data=(x_input_validate, x_input_validate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n",
      "\u001b[0;32m~/.conda/envs/Basics/lib/python3.6/site-packages/ngdlm/models/ae.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Basics/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/Basics/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Basics/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Basics/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Basics/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train.\n",
    "print(\"Train...\")\n",
    "history = autoencoder.fit(\n",
    "        x_input_train, x_input_train,\n",
    "        epochs=10,\n",
    "        batch_size=1,\n",
    "        shuffle=True\n",
    "        #validation_data=(x_input_validate, x_input_validate)\n",
    "    )\n",
    "\n",
    "# Evaluate.\n",
    "#print(\"Evaluate...\")\n",
    "#loss = autoencoder.evaluate(x_input_test, x_input_test)\n",
    "#print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_input_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_input_train[i].reshape((128,128)), cmap = \"gray\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape((128, 128)), cmap = \"gray\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
